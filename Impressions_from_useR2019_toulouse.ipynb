{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks serves the purpose of sharing my impressions from the [*UseR2019 conference*](http://www.user2019.fr/) held in Toulouse July 8-12th 2019.\n",
    "\n",
    "**Who?** Me: Marija Majer, [github page](https://github.com/mima25)\n",
    "\n",
    "**Why?** As a practicing data scientist who uses both Python and R, but is surrounded by Python users in my daily job, I thought it would be a great idea to catch up with R users and hear about latest advances and trends in using R for data science. Spoiler alert: the conference nailed it for the described purpose.\n",
    "\n",
    "**Where?** Well, you haven´t really read the first sentence in the introduction if you´re still wondering.\n",
    "\n",
    "\n",
    "Below a photo hint:\n",
    "\n",
    "\n",
    "<img style=\"float: right; transform: rotate(90deg)\" width=\"350\" src=\"images/IMG_3111.JPG\" title = \"Ariane 5 mock-up at Cité de l'Espace in Toulouse\"/>\n",
    "<img src=\"images/toulouse_panorama.JPG\" title=\"Toulouse panorama by the banks of Garonne\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keynotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R for better science in less time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia Stewart Lowndes gave a really nice talk about how to do data science when you´re facing a culture that needs to turn towards open source science, data driven approaches, collaboration in teams etc etc. She gave examples of how analytical flows were established in her team at NCEAS, talking to the mindset shift towards both vertical and horizontal leadership in data science teams, combined with open source collaborations that have a positive feedback loop with reproducibility. All of this was in context of her environmental science work (check [Openscapes](https://www.openscapes.org/)), that made me even more excited about her talk. But bottom line was don´t be scared to be transformative and to embrace data science!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A missing value tour in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another talk with reference and examples to the bioscience domain, which is very relevant for my work. Julie Josse gave a nice overview of all the packages out there that can handle missing values in the context of big data analyses and machine learning, with great references to clinical trial data and does and don´ts when you´re missing data. My main takeaway was that imputation by means is ok for predictions, but aboslutely inacceptable for effect estimates and correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shiny's Holy Grail: Interactivity with reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chief Technology Officer at RStudio, Joe Chang, gave a fantastic talk on interactivity with reproducibility, talking to the daily struggles I and the rest of my team have when developing analytical worksflows that are delivered as web based applications to our stakeholders. He apparently wrote the talk abstract before having the solution for interactivity vs. reproduciblity in shiny (THE library for web based applications in R); an approach he didn´t recommend to anyone. Still an approach totally familiar to me, cause all the conference talks I ever gave as a researcher were always started as ideas on what I´d like to do next in my research, writting down the abstract, and a month/week before the conference juggling up some analyses to work out the concept. I´d say in my case it resulted in many good talks, and subsequent papers, so not to be completely dismissed... :)\n",
    "\n",
    "So the gist of the talk was this: you build up a nice app with ultra cool models in the backend, and the user wants to save the flow once (s)he has ran models and simulated whatever it is the app should do. BUT, how do you do that?  So you have nice interactivity, but how do you allow the user to ever repeat the flow/get same (similar) results? Until today the situation, both in Python and R based applications - to my best knowledge, was excluding reproducibility on the account of interactivity.\n",
    "\n",
    "So there´s a newly emerged shiny solution for it just packaged on CRAN (though still beta version): [shinymeta](https://github.com/rstudio/shinymeta).\n",
    "Awesome talk, both conceptually and how it was delivered!\n",
    "<img src=\"images/IMG_3117.JPG\" title=\"Joe Chang on shinymeta at useR2019\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools for Model-Based Clustering in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a talk that would make an awesome review paper. Pretty dry, but I´m sure at some point I´ll find it useful. For anyone interested, here´s a [comprehensive overview of CRAN clustering tasks](https://cran.r-project.org/web/views/Cluster.html) with all the most recent packages listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'AI for Good' in the R and Python ecosystems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was another great talk, presented by Julien Cornebise, Director of Research at Element AI, that resonated with my as a data science practitioner. He expanded from not just R and Python ecosystems (again resonating with me as R first, and then came everything else), but also mentioned his dive into Lua (whaaat?) at DeepMind. It was a well delivered talk, that moreover confirmed my strong beliefs in environmental influences on the behavior of individuals (FYI I´m an ecologist by training).\n",
    "\n",
    "If you have yourself ever been torn in a dilemma between how cool to go with the models vs. how to deliver USABLE and USEFUL data science solutions to the stakeholders, here´s the summary tips for you (I especially loved the Github cemetary of hackathon projects analogy, oh have we been there or what?!): \n",
    "\n",
    "* Path to concrete impact? Batting average vs. 'measure'\n",
    "* Get rid of hype\n",
    "* No 'Tech Savior', no 'White Savior'\n",
    "* Identify right depth of tech\n",
    "* Hard questions to researchers:\n",
    "    * *Are you here to solve a problem?*\n",
    "    * *or to illustrate your method?*\n",
    "* Plan for sustainability - long development:\n",
    "    * Hackathon syndrome: Github as a cemetary\n",
    "    * Beyond research: are there engineers and designers?\n",
    "    \n",
    "    \n",
    "<img src=\"images/IMG_3141.JPG\" title=\"Julien Cornebise on rivalry and complementing of tools available for data science at useR2019\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a wide range of topics, concepts and packages covered in the lightning talks sessions, but I´ll mention only one here.\n",
    "\n",
    "So I totally randomly bumped into an old colleague from Ben-Gurion University of the Negev. When we last met I was finishing my postdoc there, and she was doing her masters degree. Fast forward to 2019, where we´re both doing data science in the private sector, and enjoying it. We reflected on the good old days in the amazing Sde Boker campus in Israel, and all the perks of switching from academia to the industry.\n",
    "She´s meanwhile also done an intership at RStudio, and gave a great speed talk on her awesome work on a package for data science puzzles. RStudio is hopefully gonna release it soon, and it makes for an awesome R version of datacamping to learn data wrangling. I´d say the concept is even more appealing than DataCamp courses, since you actually do things only in the software interface itself (no videos, but thinking and talking to yourself). Kudus to the team! You can check the gist of the package [here](https://github.com/isteves/ds-puzzles). FYI the name derives from a Shakespeare scene of the [Tragedy of Julius Caesar](https://en.wikipedia.org/wiki/Assassination_of_Julius_Caesar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic deep dive talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a range of really interesting 20min talks divided into several sessions:\n",
    "* Applications\n",
    "* Bioinformatics\n",
    "* Biostatistics & epidemiology\n",
    "* Data handling\n",
    "* Open science, education & community\n",
    "* Programming \n",
    "* Reproducibility\n",
    "* Shiny\n",
    "* Social science, marketing & business\n",
    "* Text mining\n",
    "* Workflow & development\n",
    "\n",
    "& plenty more... This was just to illustrate there was something for everyone IMHO.\n",
    "\n",
    "I´ll mention two that I found particuarly useful and amusing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colin Gillespie on R and security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an awesome comedy show performance on security issues when deplying you apps and/or running code examples from blogs. It featured hacking, domain squatting and techniques for guessing  passwords on RStudio server instances. It made us all both laugh and think very hard about how we do stuff (in data science, not just in R!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadley Wickam on Enhancements to data tidying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadley figured his gather() and spread() functions from the tidy package weren´t very well documented, so he presented two new functions to clear that out. Even though I disagree and think it´s pretty self evident from function names themselves what the functions are supposed to do, here are the new functions you can check out : [pivot_longer](https://rdrr.io/github/tidyverse/tidyr/man/pivot_longer.html) and [pivot_wider](https://rdrr.io/github/tidyverse/tidyr/man/pivot_wider.html).\n",
    "And he pulled a live regexing session, lucky for him it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising High-Dimensional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found it not that exciting, since I´ve been doing a lot of visualizations and especially playing with color gradients and overlayed plots for my spatial analytics projects back in the days. The last half hour were the most interesting, but we unfortunately ran out of time to deep dive into tricks for visualising trully high-D data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bnlearn: Practical Bayesian Networks in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was more like a 3hour lecture than a hands on tutorial, but very useful still. Marco Scutari gave as a great intro on bayesian networks and how and when to use them for inference. Even better, most of his examples were based on clinical trial data. Again very relevant for my work. Since it was more of a lecture, I'm including all the scribbled notes below, but the take home message I got was that you need to trust your networks enough before infering causation from them (common logic, but ok to repeat). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### My notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Conditional gaussian bn: continuous vars can be conditioned by categoricals, but not the other way around (as they´re mixture of multinomials)\n",
    "- you´re not trying to infer all the combinations\n",
    "\n",
    "* Learning: model estimation can be done via local distribution inference ( in both structure and parameter learning), which is mathematically neat\n",
    "Much of literature on sparse graphs, cause any exponential complexities take forever to learn and not much research done on them\n",
    "\n",
    "* Inference: computing conditional probabilities and prediction; can do both by sampling (propagation in case of sparse networks)\n",
    "Don´t have to fix all distributions, can change only the marginal distributions...\n",
    "MAP: combinatorial space, and computationally challenging but easier to do if phrased as a prediction tas. Can get computionally challenging whenever there are discrete vars.\n",
    "\n",
    "bn.fit(): named list of local distributions\n",
    "\n",
    "Graph structure gives you the parameter structures, but not values.\n",
    "Crucial to explore vars that express similar facts, can end up with clusters of vars that are linked by arcs > model stops being sparse, and graph impossible to read.\n",
    "Make sure vars are orthogonal in meaning as much as they can be.\n",
    "\n",
    "tiers2blacklist(): if a set of variables that are stacked, so can white/blacklist topology\n",
    "\n",
    "Before fitting parameters you want to make sure the arcsa are really there, so get their confidence intervals.\n",
    "Learning parameteres: high correlation not an issue as you get a set of parents without colinear nodes.\n",
    "\n",
    "* Model validation: Confidence intervals dependent on the number of simulations, so no real world interpretation.\n",
    "Casual query for of treatment effect for clinical trial validation...removing arcs pointing to the target var. Simulating the condition in which you forcibly set the pacients to evolve condition the way you want.\n",
    "Setting the intercept to 0 and removing everything else confirmed the casual effect of treatment.\n",
    "\n",
    "For observational data at some point you need to arbitrarily set directions, since you cannot assume causation implicitly on such data with structural learning approached. \n",
    "Big assumption for this to work on obs data: no latent confounder in the data!\n",
    "Cannot rule out arcs that have treatment effect going somewhere else, since no randomization and possible unobserved variables.\n",
    "\n",
    "* Take home message: you need to trust your network enough to infer causation.\n",
    "\n",
    "DBN: nodes pointing to nodes in later point in time, resembling autoregressive models. \n",
    "Need to duplicate nodes across time points, and blacklist all arcs that go from timepoint 2>1 (against the time direction).\n",
    "Modeling different values at different points in time, so can have queries on evolution of condition. \n",
    "\n",
    "Accuracy in cross validation: on the posteriors.\n",
    "Just need to be very aware that this model is linear, so don´t trust the step but the trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conference dinner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was held at the already pictured Cité de l'Espace, an outdoor thematic park with models of all sorts of rockets and satellite stations. We had cool live music by a mixed Moroccan-Spanish-French band, pictured below playing below the Mir space station. Fun, but food was not French...   \n",
    "\n",
    "<img src=\"images/IMG_3112.JPG\" title=\"Live music at useR2019 conference dinner held at Cité de l'espace\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conference aftermath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was fun to attend and meet a crowd of people with very similar life trajectories to me, like switching from academia (often bioscience) to doing data science in the industry, living abroad, supporting and using open source tools for their work etc etc... \n",
    "I got a great overview of the latest advances in modelling, programming, deploying and productionalizing data science projects. There was many great talks on the fluffy stuff around coping with traditional hierarchies and mindsets as a data scientist in the 21st century. The future has many challenges for sure, but data science (in R) is gonna be part of it (c'est la vie for all ya Python people!).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
